{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "890f05de-686b-4332-83fd-8b46a79febcf",
   "metadata": {},
   "source": [
    "# <span style=\"color:darkred; font-weight:bold;\">COMP5606 - Natural Language Processing - FALL 2024</span>\n",
    "\n",
    "---\n",
    "\n",
    "## <span style=\"color:black; font-weight:bold;\">NLP Project: Named Entity Recognition (NER) or De-identification of PHI</span>\n",
    "\n",
    "---\n",
    "\n",
    "### <span style=\"color:darkred; font-weight:bold;\">Team Members</span>  \n",
    "- <span style=\"color:darkred;\"></span> - <span style=\"color:darkred; font-style:italic;\">Ethar Al Tamimi</span>  \n",
    "- <span style=\"color:darkred;\"></span> - <span style=\"color:darkred; font-style:italic;\">Iman Al Hajri</span>  \n",
    "- <span style=\"color:darkred;\"></span> - <span style=\"color:darkred; font-style:italic;\">Malak Al Hinai</span>  \n",
    "\n",
    "---\n",
    "\n",
    "### <span style=\"color:darkred; font-weight:bold;\">Task</span>  \n",
    "Identify the following entities from medical reports:  \n",
    "- <span style=\"color:black;\">**Person Name**</span>  \n",
    "- <span style=\"color:black;\">**Location**</span>  \n",
    "- <span style=\"color:black;\">**Dates**</span>  \n",
    "- <span style=\"color:black;\">**Age**</span>  \n",
    "\n",
    "---\n",
    "\n",
    "### <span style=\"color:darkred; font-weight:bold;\">Goal</span>  \n",
    "This project aims to <span style=\"color:black; font-weight:bold;\">detect and de-identify Protected Health Information (PHI)</span> by developing a <span style=\"color:black; font-weight:bold;\">Named Entity Recognition (NER)</span> technique for medical records obtained from a hospital's electronic health system.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0f35d8-79a2-4930-a0ed-bcd97fa9d362",
   "metadata": {},
   "source": [
    "## <span style=\"color:darkred; font-weight:bold;\">Strategy 1: NER with linear SVM  </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8427beb6",
   "metadata": {},
   "source": [
    "This strategy uses Support Vector Machines (SVMs) to extract and classify entities in Named Entity Recognition (NER) tasks. The SVM-based approach employs handcrafted features to represent tokens and uses a classifier to assign one of four predefined entity categories to each token in a given text.\n",
    "### Full Pipeline:\n",
    "1. **Feature Extraction:** \n",
    "    - **`extract_features_from_text`** function extracts features for each token in the text and the features are:\n",
    "        - Is the word capitalized?\n",
    "        - Is it numeric?\n",
    "        - Prefix and suffix analysis (first two and last two letters of the token).\n",
    "        - Contextual features which are the previous and next word.\n",
    "\n",
    "\n",
    "2. **Training the SVM:**\n",
    "    - The model is trained using a **LinearSVC classifier** pipeline that includes:\n",
    "    - Feature vectorization using **DictVectorizer**.\n",
    "    - Scaling features with **StandardScaler** to improve SVM performance.\n",
    "    - Balanced class weights to address potential class imbalances in the training data.\n",
    "  \n",
    "3. **Prediction:**\n",
    "     - During prediction, tokens from new text are processed to extract features, and the trained SVM assigns an entity tag to each token. Tokens with the same entity type and contiguous positions are merged into a single entity span.\n",
    "\n",
    "4. **Output:**\n",
    " - Results are saved as CSV files containing the start and end indices of each entity, the predicted tag, and the extracted text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "821b4e97-a706-4293-bd42-8c370ab3db50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/iman/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/iman/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b399e5",
   "metadata": {},
   "source": [
    "### Extract features for the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f83df9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_text(text):\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    all_features = []\n",
    "    tokens = []\n",
    "    for sentence in sentences:\n",
    "        words = nltk.word_tokenize(sentence)\n",
    "        for i, word in enumerate(words):\n",
    "            if \",\" in word or '\"' in word or \"=\" in word:\n",
    "                continue\n",
    "            tokens.append(word)\n",
    "            previous_word = words[i - 1] if i > 0 else None\n",
    "            next_word = words[i + 1] if i < len(words) - 1 else None\n",
    "            features = {\n",
    "                \"word\": word,\n",
    "                \"is_capitalized\": word[0].isupper(),\n",
    "                \"is_numeric\": word.isdigit(),\n",
    "                \"prefix_2\": word[:2],\n",
    "                \"suffix_2\": word[-2:],\n",
    "                \"prev_word\": previous_word if previous_word else \"\",\n",
    "                \"next_word\": next_word if next_word else \"\",\n",
    "            }\n",
    "            all_features.append(features)\n",
    "    return all_features, tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b617e5",
   "metadata": {},
   "source": [
    "### Prepare Train Data using anonymized_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f99306b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = 'anonymized_txt' # Train data\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith('.txt'):\n",
    "        base_name = filename[:-4]\n",
    "        csv_filename = base_name + '.csv'\n",
    "        if csv_filename in os.listdir(directory_path):\n",
    "            txt_file_path = os.path.join(directory_path, filename)\n",
    "            csv_file_path = os.path.join(directory_path, csv_filename)\n",
    "            with open(txt_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                text = file.read()\n",
    "            features, tokens = extract_features_from_text(text)\n",
    "            df = pd.read_csv(csv_file_path)\n",
    "            token_index_mapping = []\n",
    "            start = 0\n",
    "            for token in tokens:\n",
    "                start_index = text.find(token, start)\n",
    "                end_index = start_index + len(token)\n",
    "                token_index_mapping.append((token, start_index, end_index))\n",
    "                start = end_index\n",
    "            for i, (token, start_idx, end_idx) in enumerate(token_index_mapping):\n",
    "                label = \"O\"\n",
    "                for _, row in df.iterrows():\n",
    "                    if start_idx >= row[\"start\"] and end_idx <= row[\"end\"]:\n",
    "                        label = row[\"tag\"]\n",
    "                        break\n",
    "                X_train.append(features[i])\n",
    "                y_train.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36916b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'word': '``',\n",
       "  'is_capitalized': False,\n",
       "  'is_numeric': False,\n",
       "  'prefix_2': '``',\n",
       "  'suffix_2': '``',\n",
       "  'prev_word': '',\n",
       "  'next_word': 'A'},\n",
       " {'word': 'A',\n",
       "  'is_capitalized': True,\n",
       "  'is_numeric': False,\n",
       "  'prefix_2': 'A',\n",
       "  'suffix_2': 'A',\n",
       "  'prev_word': '``',\n",
       "  'next_word': '51'},\n",
       " {'word': '51',\n",
       "  'is_capitalized': False,\n",
       "  'is_numeric': True,\n",
       "  'prefix_2': '51',\n",
       "  'suffix_2': '51',\n",
       "  'prev_word': 'A',\n",
       "  'next_word': 'years'},\n",
       " {'word': 'years',\n",
       "  'is_capitalized': False,\n",
       "  'is_numeric': False,\n",
       "  'prefix_2': 'ye',\n",
       "  'suffix_2': 'rs',\n",
       "  'prev_word': '51',\n",
       "  'next_word': 'old'},\n",
       " {'word': 'old',\n",
       "  'is_capitalized': False,\n",
       "  'is_numeric': False,\n",
       "  'prefix_2': 'ol',\n",
       "  'suffix_2': 'ld',\n",
       "  'prev_word': 'years',\n",
       "  'next_word': 'female'},\n",
       " {'word': 'female',\n",
       "  'is_capitalized': False,\n",
       "  'is_numeric': False,\n",
       "  'prefix_2': 'fe',\n",
       "  'suffix_2': 'le',\n",
       "  'prev_word': 'old',\n",
       "  'next_word': 'went'},\n",
       " {'word': 'went',\n",
       "  'is_capitalized': False,\n",
       "  'is_numeric': False,\n",
       "  'prefix_2': 'we',\n",
       "  'suffix_2': 'nt',\n",
       "  'prev_word': 'female',\n",
       "  'next_word': 'to'},\n",
       " {'word': 'to',\n",
       "  'is_capitalized': False,\n",
       "  'is_numeric': False,\n",
       "  'prefix_2': 'to',\n",
       "  'suffix_2': 'to',\n",
       "  'prev_word': 'went',\n",
       "  'next_word': 'Salalah'},\n",
       " {'word': 'Salalah',\n",
       "  'is_capitalized': True,\n",
       "  'is_numeric': False,\n",
       "  'prefix_2': 'Sa',\n",
       "  'suffix_2': 'ah',\n",
       "  'prev_word': 'to',\n",
       "  'next_word': 'hospital'},\n",
       " {'word': 'hospital',\n",
       "  'is_capitalized': False,\n",
       "  'is_numeric': False,\n",
       "  'prefix_2': 'ho',\n",
       "  'suffix_2': 'al',\n",
       "  'prev_word': 'Salalah',\n",
       "  'next_word': 'for'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61f02081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'O', 'AGE', 'O', 'O', 'O', 'O', 'O', 'LOCATION', 'LOCATION']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524d00ce",
   "metadata": {},
   "source": [
    "### Training Phaze using Linear Support Vector Classifier (LinearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48bc67d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iman/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/iman/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, DictVectorizer(sparse=False)),\n",
       "                (&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;classifier&#x27;, LinearSVC(C=0.1, class_weight=&#x27;balanced&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, DictVectorizer(sparse=False)),\n",
       "                (&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;classifier&#x27;, LinearSVC(C=0.1, class_weight=&#x27;balanced&#x27;))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;DictVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.feature_extraction.DictVectorizer.html\">?<span>Documentation for DictVectorizer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>DictVectorizer(sparse=False)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;StandardScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LinearSVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.svm.LinearSVC.html\">?<span>Documentation for LinearSVC</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LinearSVC(C=0.1, class_weight=&#x27;balanced&#x27;)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vectorizer', DictVectorizer(sparse=False)),\n",
       "                ('scaler', StandardScaler()),\n",
       "                ('classifier', LinearSVC(C=0.1, class_weight='balanced'))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    (\"vectorizer\", DictVectorizer(sparse=False)),\n",
    "    (\"scaler\", StandardScaler()),  # Scaling features (important for SVM)\n",
    "    (\"classifier\", LinearSVC(\n",
    "        C=0.1,                        # Regularization parameter (best value)\n",
    "        loss=\"squared_hinge\",         # Loss function (best value)\n",
    "        penalty=\"l2\",                 # Regularization type (best value)\n",
    "        max_iter=1000,                # Maximum number of iterations\n",
    "        class_weight=\"balanced\"       # Handling class imbalance\n",
    "    ))\n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbf31e8",
   "metadata": {},
   "source": [
    "### Testing Phaze Using 21 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d079a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to: output_LinearSVC_afterTrain/p201_prostate_onc_1.csv\n",
      "Saved predictions to: output_LinearSVC_afterTrain/p102_breast_sur_5.csv\n",
      "Saved predictions to: output_LinearSVC_afterTrain/p103_breast_onc_7.csv\n",
      "Saved predictions to: output_LinearSVC_afterTrain/p230_breast_onc_18.csv\n",
      "Saved predictions to: output_LinearSVC_afterTrain/p204_prostate_onc_8.csv\n",
      "Saved predictions to: output_LinearSVC_afterTrain/p105_breast_onc_18.csv\n",
      "Saved predictions to: output_LinearSVC_afterTrain/p215_prostate_onc_6.csv\n",
      "Saved predictions to: output_LinearSVC_afterTrain/p133_prostate_onc_11.csv\n",
      "Saved predictions to: output_LinearSVC_afterTrain/p207_prostate_onc_11.csv\n",
      "Saved predictions to: output_LinearSVC_afterTrain/p135_prostate_onc_15.csv\n",
      "Saved predictions to: output_LinearSVC_afterTrain/p210_prostate_onc_2.csv\n",
      "Saved predictions to: output_LinearSVC_afterTrain/p131_prostate_onc_6.csv\n",
      "Saved predictions to: output_LinearSVC_afterTrain/p107_breast_sur_6.csv\n",
      "Saved predictions to: output_LinearSVC_afterTrain/p132_prostate_onc_4.csv\n",
      "Saved predictions to: output_LinearSVC_afterTrain/p241_breast_onc_17.csv\n",
      "Saved predictions to: output_LinearSVC_afterTrain/p104_breast_sur_10.csv\n",
      "Saved predictions to: output_LinearSVC_afterTrain/p101_breast_onc_11.csv\n",
      "Saved predictions to: output_LinearSVC_afterTrain/p220_prostate_onc_3.csv\n",
      "Saved predictions to: output_LinearSVC_afterTrain/p233_breast_onc_7.csv\n",
      "Saved predictions to: output_LinearSVC_afterTrain/p236_breast_onc_25.csv\n",
      "Saved predictions to: output_LinearSVC_afterTrain/p106_breast_onc_19.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "txt_folder_path = \"to test\"\n",
    "predicted_folder = \"output_LinearSVC_afterTrain\"\n",
    "\n",
    "\n",
    "if not os.path.exists(predicted_folder):\n",
    "    os.makedirs(predicted_folder)\n",
    "\n",
    "for filename in os.listdir(txt_folder_path):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        txt_path = os.path.join(txt_folder_path, filename)\n",
    "        with open(txt_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            text = file.read()\n",
    "        \n",
    "        features, tokens = extract_features_from_text(text)\n",
    "        predictions = clf.predict(features)\n",
    "\n",
    "        token_index_mapping = []\n",
    "        start = 0\n",
    "        for token in tokens:\n",
    "            start_index = text.find(token, start)\n",
    "            end_index = start_index + len(token)\n",
    "            token_index_mapping.append((token, start_index, end_index))\n",
    "            start = end_index\n",
    "        \n",
    "        merged_data = []\n",
    "        current_tag = None\n",
    "        current_start = None\n",
    "        current_end = None\n",
    "        current_words = []\n",
    "\n",
    "        for (token, start_idx, end_idx), tag in zip(token_index_mapping, predictions):\n",
    "            if tag != \"O\":\n",
    "                if tag == current_tag:\n",
    "                    current_end = end_idx\n",
    "                    current_words.append(token)\n",
    "                else:\n",
    "                    if current_tag is not None:\n",
    "                        merged_data.append([current_start, current_end, current_tag, \" \".join(current_words)])\n",
    "                    current_tag = tag\n",
    "                    current_start = start_idx\n",
    "                    current_end = end_idx\n",
    "                    current_words = [token]\n",
    "            else:\n",
    "                if current_tag is not None:\n",
    "                    merged_data.append([current_start, current_end, current_tag, \" \".join(current_words)])\n",
    "                    current_tag = None\n",
    "                    current_words = []\n",
    "\n",
    "        if current_tag is not None:\n",
    "            merged_data.append([current_start, current_end, current_tag, \" \".join(current_words)])\n",
    "        \n",
    "        output_csv_path = os.path.join(predicted_folder, filename.replace(\".txt\", \".csv\"))\n",
    "        df_predicted = pd.DataFrame(merged_data, columns=[\"start\", \"end\", \"tag\", \"word\"])\n",
    "        df_predicted.to_csv(output_csv_path, index=False)\n",
    "        print(f\"Saved predictions to: {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027de66b",
   "metadata": {},
   "source": [
    "### Display The Result in tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c37fece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table from file: p104_breast_sur_10.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>tag</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71</td>\n",
       "      <td>73</td>\n",
       "      <td>AGE</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>118</td>\n",
       "      <td>131</td>\n",
       "      <td>DATE</td>\n",
       "      <td>November/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>414</td>\n",
       "      <td>423</td>\n",
       "      <td>DATE</td>\n",
       "      <td>20/5/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>494</td>\n",
       "      <td>496</td>\n",
       "      <td>AGE</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>564</td>\n",
       "      <td>568</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>ASTR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>591</td>\n",
       "      <td>600</td>\n",
       "      <td>DATE</td>\n",
       "      <td>26/7/2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start  end       tag           word\n",
       "0     71   73       AGE             61\n",
       "1    118  131      DATE  November/2023\n",
       "2    414  423      DATE      20/5/2024\n",
       "3    494  496       AGE             70\n",
       "4    564  568  LOCATION           ASTR\n",
       "5    591  600      DATE      26/7/2024"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table from file: p215_prostate_onc_6.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>tag</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>31</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>Abdallah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>195</td>\n",
       "      <td>198</td>\n",
       "      <td>NAME</td>\n",
       "      <td>Has</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>561</td>\n",
       "      <td>567</td>\n",
       "      <td>DATE</td>\n",
       "      <td>5/9/16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>714</td>\n",
       "      <td>721</td>\n",
       "      <td>DATE</td>\n",
       "      <td>18/5/14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>957</td>\n",
       "      <td>959</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>NM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start  end       tag      word\n",
       "0     23   31  LOCATION  Abdallah\n",
       "1    195  198      NAME       Has\n",
       "2    561  567      DATE    5/9/16\n",
       "3    714  721      DATE   18/5/14\n",
       "4    957  959  LOCATION        NM"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table from file: p233_breast_onc_7.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>tag</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>280</td>\n",
       "      <td>281</td>\n",
       "      <td>DATE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>298</td>\n",
       "      <td>307</td>\n",
       "      <td>DATE</td>\n",
       "      <td>23/1/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>340</td>\n",
       "      <td>348</td>\n",
       "      <td>DATE</td>\n",
       "      <td>Dec 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>461</td>\n",
       "      <td>475</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>Nizwa hospital</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1197</td>\n",
       "      <td>1210</td>\n",
       "      <td>DATE</td>\n",
       "      <td>december 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1469</td>\n",
       "      <td>1477</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>Hormonal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1756</td>\n",
       "      <td>1765</td>\n",
       "      <td>DATE</td>\n",
       "      <td>28/5/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2207</td>\n",
       "      <td>2217</td>\n",
       "      <td>DATE</td>\n",
       "      <td>33/08/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2890</td>\n",
       "      <td>2894</td>\n",
       "      <td>DATE</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2984</td>\n",
       "      <td>2986</td>\n",
       "      <td>DATE</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3059</td>\n",
       "      <td>3060</td>\n",
       "      <td>DATE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3534</td>\n",
       "      <td>3543</td>\n",
       "      <td>DATE</td>\n",
       "      <td>29/7/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3588</td>\n",
       "      <td>3589</td>\n",
       "      <td>DATE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3780</td>\n",
       "      <td>3789</td>\n",
       "      <td>DATE</td>\n",
       "      <td>pathology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4000</td>\n",
       "      <td>4004</td>\n",
       "      <td>NAME</td>\n",
       "      <td>Side</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    start   end       tag            word\n",
       "0     280   281      DATE               2\n",
       "1     298   307      DATE       23/1/2015\n",
       "2     340   348      DATE        Dec 2016\n",
       "3     461   475  LOCATION  Nizwa hospital\n",
       "4    1197  1210      DATE   december 2011\n",
       "5    1469  1477  LOCATION        Hormonal\n",
       "6    1756  1765      DATE       28/5/2021\n",
       "7    2207  2217      DATE      33/08/2021\n",
       "8    2890  2894      DATE            2006\n",
       "9    2984  2986      DATE              23\n",
       "10   3059  3060      DATE               2\n",
       "11   3534  3543      DATE       29/7/2016\n",
       "12   3588  3589      DATE               2\n",
       "13   3780  3789      DATE       pathology\n",
       "14   4000  4004      NAME            Side"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table from file: p201_prostate_onc_1.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>tag</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>DATE</td>\n",
       "      <td>Dec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52</td>\n",
       "      <td>59</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>Solomon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73</td>\n",
       "      <td>85</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>SQU Hospital</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>118</td>\n",
       "      <td>132</td>\n",
       "      <td>NAME</td>\n",
       "      <td>Abdulhafid Al</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>144</td>\n",
       "      <td>148</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>Ibri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>719</td>\n",
       "      <td>732</td>\n",
       "      <td>NAME</td>\n",
       "      <td>Nafaan Hashim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1056</td>\n",
       "      <td>1074</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>Mauritius Hospital</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1512</td>\n",
       "      <td>1517</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>FAMCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1989</td>\n",
       "      <td>1995</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>Muscat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start   end       tag                word\n",
       "0      0     3      DATE                 Dec\n",
       "1     52    59  LOCATION             Solomon\n",
       "2     73    85  LOCATION        SQU Hospital\n",
       "3    118   132      NAME       Abdulhafid Al\n",
       "4    144   148  LOCATION                Ibri\n",
       "5    719   732      NAME       Nafaan Hashim\n",
       "6   1056  1074  LOCATION  Mauritius Hospital\n",
       "7   1512  1517  LOCATION               FAMCO\n",
       "8   1989  1995  LOCATION              Muscat"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table from file: p107_breast_sur_6.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>tag</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>137</td>\n",
       "      <td>145</td>\n",
       "      <td>DATE</td>\n",
       "      <td>dec 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>370</td>\n",
       "      <td>380</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>sohar hspt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>504</td>\n",
       "      <td>514</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>Sohar hspt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>518</td>\n",
       "      <td>526</td>\n",
       "      <td>DATE</td>\n",
       "      <td>Mar 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>737</td>\n",
       "      <td>745</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>Pakistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>749</td>\n",
       "      <td>760</td>\n",
       "      <td>DATE</td>\n",
       "      <td>22 may 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2489</td>\n",
       "      <td>2499</td>\n",
       "      <td>DATE</td>\n",
       "      <td>11/07/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2911</td>\n",
       "      <td>2921</td>\n",
       "      <td>DATE</td>\n",
       "      <td>30/08/2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start   end       tag         word\n",
       "0    137   145      DATE     dec 2015\n",
       "1    370   380  LOCATION   sohar hspt\n",
       "2    504   514  LOCATION   Sohar hspt\n",
       "3    518   526      DATE     Mar 2016\n",
       "4    737   745  LOCATION     Pakistan\n",
       "5    749   760      DATE  22 may 2016\n",
       "6   2489  2499      DATE   11/07/2016\n",
       "7   2911  2921      DATE   30/08/2016"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table from file: p207_prostate_onc_11.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>tag</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [start, end, tag, word]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table from file: p102_breast_sur_5.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>tag</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>AGE</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>47</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>Salalah hospital</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>388</td>\n",
       "      <td>396</td>\n",
       "      <td>DATE</td>\n",
       "      <td>8/4/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>613</td>\n",
       "      <td>629</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>salalah hospital</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start  end       tag              word\n",
       "0      3    5       AGE                51\n",
       "1     31   47  LOCATION  Salalah hospital\n",
       "2    388  396      DATE          8/4/2014\n",
       "3    613  629  LOCATION  salalah hospital"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table from file: p204_prostate_onc_8.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>tag</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>45</td>\n",
       "      <td>NAME</td>\n",
       "      <td>iftikhar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52</td>\n",
       "      <td>67</td>\n",
       "      <td>NAME</td>\n",
       "      <td>rahim Al suqri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>816</td>\n",
       "      <td>817</td>\n",
       "      <td>DATE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>907</td>\n",
       "      <td>908</td>\n",
       "      <td>DATE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1613</td>\n",
       "      <td>1621</td>\n",
       "      <td>DATE</td>\n",
       "      <td>apr 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2232</td>\n",
       "      <td>2241</td>\n",
       "      <td>DATE</td>\n",
       "      <td>27/2/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2410</td>\n",
       "      <td>2414</td>\n",
       "      <td>DATE</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3081</td>\n",
       "      <td>3082</td>\n",
       "      <td>DATE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>384</td>\n",
       "      <td>385</td>\n",
       "      <td>DATE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start   end   tag            word\n",
       "0     37    45  NAME        iftikhar\n",
       "1     52    67  NAME  rahim Al suqri\n",
       "2    816   817  DATE               2\n",
       "3    907   908  DATE               2\n",
       "4   1613  1621  DATE        apr 2016\n",
       "5   2232  2241  DATE       27/2/2016\n",
       "6   2410  2414  DATE            2011\n",
       "7   3081  3082  DATE               2\n",
       "8    384   385  DATE               2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table from file: p236_breast_onc_25.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>tag</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>318</td>\n",
       "      <td>328</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>Ibra 2008.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>473</td>\n",
       "      <td>481</td>\n",
       "      <td>DATE</td>\n",
       "      <td>Jun 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>620</td>\n",
       "      <td>629</td>\n",
       "      <td>DATE</td>\n",
       "      <td>30/4/2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>886</td>\n",
       "      <td>894</td>\n",
       "      <td>DATE</td>\n",
       "      <td>Dec 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1038</td>\n",
       "      <td>1042</td>\n",
       "      <td>DATE</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1216</td>\n",
       "      <td>1220</td>\n",
       "      <td>NAME</td>\n",
       "      <td>Huda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1504</td>\n",
       "      <td>1508</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>Iron</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start   end       tag        word\n",
       "0    318   328  LOCATION  Ibra 2008.\n",
       "1    473   481      DATE    Jun 2015\n",
       "2    620   629      DATE   30/4/2012\n",
       "3    886   894      DATE    Dec 2014\n",
       "4   1038  1042      DATE        2015\n",
       "5   1216  1220      NAME        Huda\n",
       "6   1504  1508  LOCATION        Iron"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table from file: p101_breast_onc_11.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>tag</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>NAME</td>\n",
       "      <td>Harmal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201</td>\n",
       "      <td>207</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>233</td>\n",
       "      <td>239</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2257</td>\n",
       "      <td>2263</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2398</td>\n",
       "      <td>2408</td>\n",
       "      <td>DATE</td>\n",
       "      <td>20/11/2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3491</td>\n",
       "      <td>3497</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3612</td>\n",
       "      <td>3622</td>\n",
       "      <td>DATE</td>\n",
       "      <td>20/11/2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start   end       tag        word\n",
       "0     13    19      NAME      Harmal\n",
       "1    201   207  LOCATION      France\n",
       "2    233   239  LOCATION      France\n",
       "3   2257  2263  LOCATION      France\n",
       "4   2398  2408      DATE  20/11/2010\n",
       "5   3491  3497  LOCATION      France\n",
       "6   3612  3622      DATE  20/11/2010"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table from file: p132_prostate_onc_4.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>tag</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "      <td>60</td>\n",
       "      <td>NAME</td>\n",
       "      <td>Sinan Habib Amer Al-Hinai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>97</td>\n",
       "      <td>103</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>Muscat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115</td>\n",
       "      <td>118</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>SQU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>409</td>\n",
       "      <td>414</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>FAMCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>442</td>\n",
       "      <td>456</td>\n",
       "      <td>DATE</td>\n",
       "      <td>September 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>708</td>\n",
       "      <td>720</td>\n",
       "      <td>DATE</td>\n",
       "      <td>October 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>751</td>\n",
       "      <td>765</td>\n",
       "      <td>DATE</td>\n",
       "      <td>March 13 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>774</td>\n",
       "      <td>784</td>\n",
       "      <td>DATE</td>\n",
       "      <td>17/04/2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1114</td>\n",
       "      <td>1123</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>Indonesia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1433</td>\n",
       "      <td>1443</td>\n",
       "      <td>DATE</td>\n",
       "      <td>11/08/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1452</td>\n",
       "      <td>1462</td>\n",
       "      <td>DATE</td>\n",
       "      <td>11/08/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1849</td>\n",
       "      <td>1862</td>\n",
       "      <td>DATE</td>\n",
       "      <td>February 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2463</td>\n",
       "      <td>2472</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>Indonesia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    start   end       tag                       word\n",
       "0      35    60      NAME  Sinan Habib Amer Al-Hinai\n",
       "1      97   103  LOCATION                     Muscat\n",
       "2     115   118  LOCATION                        SQU\n",
       "3     409   414  LOCATION                      FAMCO\n",
       "4     442   456      DATE             September 2012\n",
       "5     708   720      DATE               October 2012\n",
       "6     751   765      DATE              March 13 2013\n",
       "7     774   784      DATE                 17/04/2013\n",
       "8    1114  1123  LOCATION                  Indonesia\n",
       "9    1433  1443      DATE                 11/08/2014\n",
       "10   1452  1462      DATE                 11/08/2014\n",
       "11   1849  1862      DATE              February 2012\n",
       "12   2463  2472  LOCATION                  Indonesia"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table from file: p133_prostate_onc_11.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>tag</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>203</td>\n",
       "      <td>209</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>Kuwait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>349</td>\n",
       "      <td>359</td>\n",
       "      <td>DATE</td>\n",
       "      <td>20/03/2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start  end       tag        word\n",
       "0    203  209  LOCATION      Kuwait\n",
       "1    349  359      DATE  20/03/2024"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table from file: p106_breast_onc_19.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>tag</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "      <td>NAME</td>\n",
       "      <td>Amr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>121</td>\n",
       "      <td>134</td>\n",
       "      <td>DATE</td>\n",
       "      <td>Decemebr 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>324</td>\n",
       "      <td>328</td>\n",
       "      <td>DATE</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>353</td>\n",
       "      <td>357</td>\n",
       "      <td>DATE</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>361</td>\n",
       "      <td>365</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>Iran</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>476</td>\n",
       "      <td>480</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>Seeb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>521</td>\n",
       "      <td>524</td>\n",
       "      <td>DATE</td>\n",
       "      <td>JAn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>584</td>\n",
       "      <td>587</td>\n",
       "      <td>DATE</td>\n",
       "      <td>Feb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1865</td>\n",
       "      <td>1875</td>\n",
       "      <td>DATE</td>\n",
       "      <td>6 July2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start   end       tag           word\n",
       "0     19    22      NAME            Amr\n",
       "1    121   134      DATE  Decemebr 2011\n",
       "2    324   328      DATE           2000\n",
       "3    353   357      DATE           2004\n",
       "4    361   365  LOCATION           Iran\n",
       "5    476   480  LOCATION           Seeb\n",
       "6    521   524      DATE            JAn\n",
       "7    584   587      DATE            Feb\n",
       "8   1865  1875      DATE     6 July2021"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table from file: p103_breast_onc_7.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>tag</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>NAME</td>\n",
       "      <td>Amira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>AGE</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>562</td>\n",
       "      <td>584</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>Shifa Alhayat Hospital</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1082</td>\n",
       "      <td>1085</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>NMC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2573</td>\n",
       "      <td>2582</td>\n",
       "      <td>DATE</td>\n",
       "      <td>18/6/2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3731</td>\n",
       "      <td>3744</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>Ibra hospital</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3834</td>\n",
       "      <td>3843</td>\n",
       "      <td>DATE</td>\n",
       "      <td>11/4/2006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start   end       tag                    word\n",
       "0      0     5      NAME                   Amira\n",
       "1      9    11       AGE                      51\n",
       "2    562   584  LOCATION  Shifa Alhayat Hospital\n",
       "3   1082  1085  LOCATION                     NMC\n",
       "4   2573  2582      DATE               18/6/2006\n",
       "5   3731  3744  LOCATION           Ibra hospital\n",
       "6   3834  3843      DATE               11/4/2006"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table from file: p105_breast_onc_18.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>tag</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>260</td>\n",
       "      <td>262</td>\n",
       "      <td>AGE</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>643</td>\n",
       "      <td>652</td>\n",
       "      <td>DATE</td>\n",
       "      <td>12/2/2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>677</td>\n",
       "      <td>686</td>\n",
       "      <td>DATE</td>\n",
       "      <td>15/3/2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start  end   tag       word\n",
       "0    260  262   AGE         47\n",
       "1    643  652  DATE  12/2/2012\n",
       "2    677  686  DATE  15/3/2012"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table from file: p135_prostate_onc_15.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>tag</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>223</td>\n",
       "      <td>228</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>Qatar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250</td>\n",
       "      <td>260</td>\n",
       "      <td>DATE</td>\n",
       "      <td>17/10/2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>741</td>\n",
       "      <td>751</td>\n",
       "      <td>DATE</td>\n",
       "      <td>10/07/2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>807</td>\n",
       "      <td>813</td>\n",
       "      <td>DATE</td>\n",
       "      <td>August</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1437</td>\n",
       "      <td>1447</td>\n",
       "      <td>DATE</td>\n",
       "      <td>07/10/2011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start   end       tag        word\n",
       "0    223   228  LOCATION       Qatar\n",
       "1    250   260      DATE  17/10/2010\n",
       "2    741   751      DATE  10/07/2011\n",
       "3    807   813      DATE      August\n",
       "4   1437  1447      DATE  07/10/2011"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table from file: p220_prostate_onc_3.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>tag</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>167</td>\n",
       "      <td>177</td>\n",
       "      <td>DATE</td>\n",
       "      <td>30/08/2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start  end   tag        word\n",
       "0    167  177  DATE  30/08/2013"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table from file: p210_prostate_onc_2.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>tag</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>42</td>\n",
       "      <td>NAME</td>\n",
       "      <td>Masiy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66</td>\n",
       "      <td>71</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>Afifa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>253</td>\n",
       "      <td>261</td>\n",
       "      <td>NAME</td>\n",
       "      <td>Suwaidan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>389</td>\n",
       "      <td>393</td>\n",
       "      <td>DATE</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>983</td>\n",
       "      <td>987</td>\n",
       "      <td>DATE</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1635</td>\n",
       "      <td>1645</td>\n",
       "      <td>DATE</td>\n",
       "      <td>16/08/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1998</td>\n",
       "      <td>2015</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>Hospita Hospital.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start   end       tag               word\n",
       "0     37    42      NAME              Masiy\n",
       "1     66    71  LOCATION              Afifa\n",
       "2    253   261      NAME           Suwaidan\n",
       "3    389   393      DATE               2012\n",
       "4    983   987      DATE               2017\n",
       "5   1635  1645      DATE         16/08/2014\n",
       "6   1998  2015  LOCATION  Hospita Hospital."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table from file: p131_prostate_onc_6.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>tag</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>69</td>\n",
       "      <td>NAME</td>\n",
       "      <td>Salman Said Mubarik Al hajri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>116</td>\n",
       "      <td>124</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>Khaboura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>229</td>\n",
       "      <td>234</td>\n",
       "      <td>NAME</td>\n",
       "      <td>Hajri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>340</td>\n",
       "      <td>342</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>SH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>579</td>\n",
       "      <td>589</td>\n",
       "      <td>DATE</td>\n",
       "      <td>21/03/2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>727</td>\n",
       "      <td>734</td>\n",
       "      <td>DATE</td>\n",
       "      <td>12/8/16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>875</td>\n",
       "      <td>885</td>\n",
       "      <td>DATE</td>\n",
       "      <td>23/11/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1071</td>\n",
       "      <td>1081</td>\n",
       "      <td>DATE</td>\n",
       "      <td>11/12/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1531</td>\n",
       "      <td>1540</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>two black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1544</td>\n",
       "      <td>1554</td>\n",
       "      <td>DATE</td>\n",
       "      <td>29/01/2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>579</td>\n",
       "      <td>580</td>\n",
       "      <td>DATE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1689</td>\n",
       "      <td>1694</td>\n",
       "      <td>NAME</td>\n",
       "      <td>Jasim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1708</td>\n",
       "      <td>1710</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>RH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    start   end       tag                          word\n",
       "0      41    69      NAME  Salman Said Mubarik Al hajri\n",
       "1     116   124  LOCATION                      Khaboura\n",
       "2     229   234      NAME                         Hajri\n",
       "3     340   342  LOCATION                            SH\n",
       "4     579   589      DATE                    21/03/2017\n",
       "5     727   734      DATE                       12/8/16\n",
       "6     875   885      DATE                    23/11/2016\n",
       "7    1071  1081      DATE                    11/12/2016\n",
       "8    1531  1540  LOCATION                     two black\n",
       "9    1544  1554      DATE                    29/01/2017\n",
       "10    579   580      DATE                             2\n",
       "11   1689  1694      NAME                         Jasim\n",
       "12   1708  1710  LOCATION                            RH"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table from file: p230_breast_onc_18.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>tag</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>271</td>\n",
       "      <td>275</td>\n",
       "      <td>DATE</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>296</td>\n",
       "      <td>297</td>\n",
       "      <td>DATE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>371</td>\n",
       "      <td>374</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>SQU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>698</td>\n",
       "      <td>700</td>\n",
       "      <td>DATE</td>\n",
       "      <td>Ki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1079</td>\n",
       "      <td>1087</td>\n",
       "      <td>DATE</td>\n",
       "      <td>dec 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1797</td>\n",
       "      <td>1798</td>\n",
       "      <td>DATE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1921</td>\n",
       "      <td>1925</td>\n",
       "      <td>DATE</td>\n",
       "      <td>30/3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2113</td>\n",
       "      <td>2121</td>\n",
       "      <td>DATE</td>\n",
       "      <td>9/6/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2295</td>\n",
       "      <td>2304</td>\n",
       "      <td>DATE</td>\n",
       "      <td>18/8/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2377</td>\n",
       "      <td>2386</td>\n",
       "      <td>DATE</td>\n",
       "      <td>33/3/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3935</td>\n",
       "      <td>3943</td>\n",
       "      <td>DATE</td>\n",
       "      <td>9/4/2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    start   end       tag       word\n",
       "0     271   275      DATE       2017\n",
       "1     296   297      DATE          2\n",
       "2     371   374  LOCATION        SQU\n",
       "3     698   700      DATE         Ki\n",
       "4    1079  1087      DATE   dec 2020\n",
       "5    1797  1798      DATE          2\n",
       "6    1921  1925      DATE       30/3\n",
       "7    2113  2121      DATE   9/6/2016\n",
       "8    2295  2304      DATE  18/8/2014\n",
       "9    2377  2386      DATE  33/3/2016\n",
       "10   3935  3943      DATE   9/4/2017"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table from file: p241_breast_onc_17.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>tag</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>315</td>\n",
       "      <td>326</td>\n",
       "      <td>DATE</td>\n",
       "      <td>August 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>508</td>\n",
       "      <td>521</td>\n",
       "      <td>DATE</td>\n",
       "      <td>February 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>561</td>\n",
       "      <td>564</td>\n",
       "      <td>DATE</td>\n",
       "      <td>May</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1133</td>\n",
       "      <td>1135</td>\n",
       "      <td>AGE</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1142</td>\n",
       "      <td>1144</td>\n",
       "      <td>DATE</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1657</td>\n",
       "      <td>1660</td>\n",
       "      <td>NAME</td>\n",
       "      <td>Had</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1740</td>\n",
       "      <td>1748</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>Mughreeb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start   end       tag           word\n",
       "0    315   326      DATE    August 2011\n",
       "1    508   521      DATE  February 2014\n",
       "2    561   564      DATE            May\n",
       "3   1133  1135       AGE             70\n",
       "4   1142  1144      DATE             16\n",
       "5   1657  1660      NAME            Had\n",
       "6   1740  1748  LOCATION       Mughreeb"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for filename in os.listdir(predicted_folder):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(predicted_folder, filename)\n",
    "        \n",
    "        \n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        \n",
    "        print(f\"Table from file: {filename}\")\n",
    "        display(df)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e990d210",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e348c99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing predicted file: p104_breast_sur_10.csv\n",
      "Processing predicted file: p215_prostate_onc_6.csv\n",
      "Processing predicted file: p233_breast_onc_7.csv\n",
      "Processing predicted file: p201_prostate_onc_1.csv\n",
      "Processing predicted file: p107_breast_sur_6.csv\n",
      "Processing predicted file: p207_prostate_onc_11.csv\n",
      "Processing predicted file: p102_breast_sur_5.csv\n",
      "Processing predicted file: p204_prostate_onc_8.csv\n",
      "Processing predicted file: p236_breast_onc_25.csv\n",
      "Processing predicted file: p101_breast_onc_11.csv\n",
      "Processing predicted file: p132_prostate_onc_4.csv\n",
      "Processing predicted file: p133_prostate_onc_11.csv\n",
      "Processing predicted file: p106_breast_onc_19.csv\n",
      "Processing predicted file: p103_breast_onc_7.csv\n",
      "Processing predicted file: p105_breast_onc_18.csv\n",
      "Processing predicted file: p135_prostate_onc_15.csv\n",
      "Processing predicted file: p220_prostate_onc_3.csv\n",
      "Processing predicted file: p210_prostate_onc_2.csv\n",
      "Processing predicted file: p131_prostate_onc_6.csv\n",
      "Processing predicted file: p230_breast_onc_18.csv\n",
      "Processing predicted file: p241_breast_onc_17.csv\n",
      "Processing true file: p104_breast_sur_10.csv\n",
      "Processing true file: p215_prostate_onc_6.csv\n",
      "Processing true file: p233_breast_onc_7.csv\n",
      "Processing true file: p201_prostate_onc_1.csv\n",
      "Processing true file: p107_breast_sur_6.csv\n",
      "Processing true file: p207_prostate_onc_11.csv\n",
      "Processing true file: p102_breast_sur_5.csv\n",
      "Processing true file: p204_prostate_onc_8.csv\n",
      "Processing true file: p236_breast_onc_25.csv\n",
      "Processing true file: p101_breast_onc_11.csv\n",
      "Processing true file: p132_prostate_onc_4.csv\n",
      "Processing true file: p133_prostate_onc_11.csv\n",
      "Processing true file: p106_breast_onc_19.csv\n",
      "Processing true file: p103_breast_onc_7.csv\n",
      "Processing true file: p105_breast_onc_18.csv\n",
      "Processing true file: p135_prostate_onc_15.csv\n",
      "Processing true file: p220_prostate_onc_3.csv\n",
      "Processing true file: p210_prostate_onc_2.csv\n",
      "Processing true file: p131_prostate_onc_6.csv\n",
      "Processing true file: p230_breast_onc_18.csv\n",
      "Processing true file: p241_breast_onc_17.csv\n",
      "\n",
      "\n",
      "Overall\n",
      "              correct   incorrect     partial      missed    spurious   precision      recall    f1-score\n",
      "\n",
      "ent_type          124           3           0          67          22        0.83        0.64        0.72\n",
      " partial          104           0          23          67          22        0.78        0.60        0.67\n",
      "  strict          104          23           0          67          22        0.70        0.54        0.61\n",
      "   exact          104          23           0          67          22        0.70        0.54        0.61\n",
      "\n",
      "\n",
      "\n",
      "'Strict'\n",
      "              correct   incorrect     partial      missed    spurious   precision      recall    f1-score\n",
      "\n",
      "     AGE            5           0           0          12           1        0.83        0.29        0.43\n",
      "    DATE           60          11           0          35          13        0.71        0.57        0.63\n",
      "LOCATION           31           5           0          14           4        0.78        0.62        0.69\n",
      "    NAME            8           7           0           6           4        0.42        0.38        0.40\n",
      "\n",
      "\n",
      "\n",
      "'Ent_Type'\n",
      "              correct   incorrect     partial      missed    spurious   precision      recall    f1-score\n",
      "\n",
      "     AGE            5           0           0          12           1        0.83        0.29        0.43\n",
      "    DATE           70           1           0          35          13        0.83        0.66        0.74\n",
      "LOCATION           36           0           0          14           4        0.90        0.72        0.80\n",
      "    NAME           13           2           0           6           4        0.68        0.62        0.65\n",
      "\n",
      "\n",
      "\n",
      "'Partial'\n",
      "              correct   incorrect     partial      missed    spurious   precision      recall    f1-score\n",
      "\n",
      "     AGE            5           0           0          12           1        0.83        0.29        0.43\n",
      "    DATE           60           0          11          35          13        0.78        0.62        0.69\n",
      "LOCATION           31           0           5          14           4        0.84        0.67        0.74\n",
      "    NAME            8           0           7           6           4        0.61        0.55        0.57\n",
      "\n",
      "\n",
      "\n",
      "'Exact'\n",
      "              correct   incorrect     partial      missed    spurious   precision      recall    f1-score\n",
      "\n",
      "     AGE            5           0           0          12           1        0.83        0.29        0.43\n",
      "    DATE           60          11           0          35          13        0.71        0.57        0.63\n",
      "LOCATION           31           5           0          14           4        0.78        0.62        0.69\n",
      "    NAME            8           7           0           6           4        0.42        0.38        0.40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from nervaluate import Evaluator, collect_named_entities, summary_report_ent, summary_report_overall\n",
    "\n",
    "# Read predicted entities\n",
    "predicted_entities = []\n",
    "for filename in os.listdir(predicted_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        print(f\"Processing predicted file: {filename}\")\n",
    "        predicted_path = os.path.join(predicted_folder, filename)\n",
    "        pred_data = pd.read_csv(predicted_path)\n",
    "        \n",
    "        doc_entities = []\n",
    "        for _, row in pred_data.iterrows():\n",
    "            doc_entities.append({\n",
    "                \"label\": row['tag'],\n",
    "                \"start\": int(row['start']),\n",
    "                \"end\": int(row['end'])\n",
    "            })\n",
    "        predicted_entities.append(doc_entities)\n",
    "\n",
    "# Read actual entities\n",
    "true_entities = []\n",
    "for filename in os.listdir(txt_folder_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        print(f\"Processing true file: {filename}\")\n",
    "        true_path = os.path.join(txt_folder_path, filename)\n",
    "        true_data = pd.read_csv(true_path)\n",
    "        \n",
    "        doc_entities = []\n",
    "        for _, row in true_data.iterrows():\n",
    "            doc_entities.append({\n",
    "                \"label\": row['tag'],\n",
    "                \"start\": int(row['start']),\n",
    "                \"end\": int(row['end'])\n",
    "            })\n",
    "        true_entities.append(doc_entities)\n",
    "\n",
    "# Run the evaluation\n",
    "\n",
    "from nervaluate import Evaluator\n",
    "from nervaluate import collect_named_entities, summary_report_ent, summary_report_overall\n",
    "\n",
    "evaluator = Evaluator(true_entities,predicted_entities, tags=['LOCATION', 'NAME', 'DATE', 'AGE'])\n",
    "results, results_per_tag, result_indices, result_indices_by_tag  = evaluator.evaluate()\n",
    "\n",
    "print(\"\\n\\nOverall\")\n",
    "print(summary_report_overall(results))\n",
    "print(\"\\n\\n'Strict'\")\n",
    "print(summary_report_ent(results_per_tag, scenario=\"strict\"))\n",
    "print(\"\\n\\n'Ent_Type'\")\n",
    "print(summary_report_ent(results_per_tag, scenario=\"ent_type\"))\n",
    "print(\"\\n\\n'Partial'\")\n",
    "print(summary_report_ent(results_per_tag, scenario=\"partial\"))\n",
    "print(\"\\n\\n'Exact'\")\n",
    "print(summary_report_ent(results_per_tag, scenario=\"exact\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0e58e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prediction new reports   \n",
    "txt_folder_path = \"test\"  # Folder containing the .txt files\n",
    "predicted_folder = \"output_csv_SVM\"  # Folder to save the CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea4100fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to: output_csv_SVM/p237_breast_onc_6.csv\n",
      "Saved predictions to: output_csv_SVM/p218_prostate_onc_2.csv\n",
      "Saved predictions to: output_csv_SVM/p253_breast_sur_2.csv\n",
      "Saved predictions to: output_csv_SVM/p219_prostate_onc_10.csv\n",
      "Saved predictions to: output_csv_SVM/p232_breast_onc_9.csv\n",
      "Saved predictions to: output_csv_SVM/p214_prostate_onc_8.csv\n",
      "Saved predictions to: output_csv_SVM/p217_prostate_onc_1.csv\n",
      "Saved predictions to: output_csv_SVM/p249_breast_sur_10.csv\n",
      "Saved predictions to: output_csv_SVM/p220_prostate_sur_6.csv\n",
      "Saved predictions to: output_csv_SVM/p248_breast_onc_13.csv\n",
      "Saved predictions to: output_csv_SVM/p256_breast_onc_11.csv\n",
      "Saved predictions to: output_csv_SVM/p238_breast_sur_4.csv\n",
      "Saved predictions to: output_csv_SVM/p251_breast_onc_82.csv\n",
      "Saved predictions to: output_csv_SVM/p235_breast_sur_5.csv\n",
      "Saved predictions to: output_csv_SVM/p228_prostate_onc_5.csv\n",
      "Saved predictions to: output_csv_SVM/p246_breast_onc_5.csv\n",
      "Saved predictions to: output_csv_SVM/p206_prostate_onc_4.csv\n",
      "Saved predictions to: output_csv_SVM/p210_prostate_onc_7.csv\n",
      "Saved predictions to: output_csv_SVM/p203_prostate_onc_10.csv\n",
      "Saved predictions to: output_csv_SVM/p257_breast_onc_7.csv\n",
      "Saved predictions to: output_csv_SVM/p225_prostate_onc_4.csv\n",
      "Saved predictions to: output_csv_SVM/p234_breast_sur_3.csv\n",
      "Saved predictions to: output_csv_SVM/p242_breast_sur_6.csv\n",
      "Saved predictions to: output_csv_SVM/p240_breast_onc_13.csv\n",
      "Saved predictions to: output_csv_SVM/p247_breast_onc_15.csv\n",
      "Saved predictions to: output_csv_SVM/p226_prostate_onc_7.csv\n",
      "Saved predictions to: output_csv_SVM/p254_breast_onc_19.csv\n",
      "Saved predictions to: output_csv_SVM/p223_prostate_onc_4.csv\n",
      "Saved predictions to: output_csv_SVM/p245_breast_onc_11.csv\n",
      "Saved predictions to: output_csv_SVM/p252_breast_sur_6.csv\n",
      "Saved predictions to: output_csv_SVM/p204_prostate_onc_23.csv\n",
      "Saved predictions to: output_csv_SVM/p224_prostate_onc_8.csv\n",
      "Saved predictions to: output_csv_SVM/p222_prostate_onc_6.csv\n",
      "Saved predictions to: output_csv_SVM/p208_prostate_onc_4.csv\n",
      "Saved predictions to: output_csv_SVM/p241_breast_sur_13.csv\n",
      "Saved predictions to: output_csv_SVM/p239_breast_onc_18.csv\n",
      "Saved predictions to: output_csv_SVM/p209_prostate_onc_3.csv\n",
      "Saved predictions to: output_csv_SVM/p213_prostate_onc_8.csv\n",
      "Saved predictions to: output_csv_SVM/p227_prostate_onc_6.csv\n",
      "Saved predictions to: output_csv_SVM/p211_prostate_onc_5.csv\n",
      "Saved predictions to: output_csv_SVM/p202_prostate_onc_1.csv\n",
      "Saved predictions to: output_csv_SVM/p244_breast_onc_13.csv\n",
      "Saved predictions to: output_csv_SVM/p229_prostate_onc_5.csv\n",
      "Saved predictions to: output_csv_SVM/p233_breast_sur_5.csv\n",
      "Saved predictions to: output_csv_SVM/p205_prostate_onc_5.csv\n",
      "Saved predictions to: output_csv_SVM/p231_breast_onc_20.csv\n",
      "Saved predictions to: output_csv_SVM/p212_prostate_onc_4.csv\n",
      "Saved predictions to: output_csv_SVM/p221_prostate_onc_7.csv\n",
      "Saved predictions to: output_csv_SVM/p216_prostate_onc_5.csv\n",
      "Saved predictions to: output_csv_SVM/p258_breast_onc_14.csv\n",
      "Saved predictions to: output_csv_SVM/p250_breast_sur_9.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if not os.path.exists(predicted_folder):\n",
    "    os.makedirs(predicted_folder)\n",
    "\n",
    "for filename in os.listdir(txt_folder_path):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        txt_path = os.path.join(txt_folder_path, filename)\n",
    "        with open(txt_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            text = file.read()\n",
    "        \n",
    "        features, tokens = extract_features_from_text(text)\n",
    "        predictions = clf.predict(features)\n",
    "\n",
    "        token_index_mapping = []\n",
    "        start = 0\n",
    "        for token in tokens:\n",
    "            start_index = text.find(token, start)\n",
    "            end_index = start_index + len(token)\n",
    "            token_index_mapping.append((token, start_index, end_index))\n",
    "            start = end_index\n",
    "        \n",
    "        merged_data = []\n",
    "        current_tag = None\n",
    "        current_start = None\n",
    "        current_end = None\n",
    "        current_words = []\n",
    "\n",
    "        for (token, start_idx, end_idx), tag in zip(token_index_mapping, predictions):\n",
    "            if tag != \"O\":\n",
    "                if tag == current_tag:\n",
    "                    current_end = end_idx\n",
    "                    current_words.append(token)\n",
    "                else:\n",
    "                    if current_tag is not None:\n",
    "                        merged_data.append([current_start, current_end, current_tag, \" \".join(current_words)])\n",
    "                    current_tag = tag\n",
    "                    current_start = start_idx\n",
    "                    current_end = end_idx\n",
    "                    current_words = [token]\n",
    "            else:\n",
    "                if current_tag is not None:\n",
    "                    merged_data.append([current_start, current_end, current_tag, \" \".join(current_words)])\n",
    "                    current_tag = None\n",
    "                    current_words = []\n",
    "\n",
    "        if current_tag is not None:\n",
    "            merged_data.append([current_start, current_end, current_tag, \" \".join(current_words)])\n",
    "        \n",
    "        output_csv_path = os.path.join(predicted_folder, filename.replace(\".txt\", \".csv\"))\n",
    "        df_predicted = pd.DataFrame(merged_data, columns=[\"start\", \"end\", \"tag\", \"word\"])\n",
    "        df_predicted.to_csv(output_csv_path, index=False)\n",
    "        print(f\"Saved predictions to: {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8202bb14",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkred; font-weight:bold;\"> Entity Extraction with SVM-Linear Evaluation Summary </span>\n",
    "**Overall Evaluation**\n",
    "\n",
    "- **Ent_Type**: \n",
    "  - **Precision**: 0.83, **Recall**: 0.64, **F1-score**: 0.72\n",
    "  - Strong precision but lower recall, indicating missed entities or spurious results.\n",
    "  \n",
    "- **Partial**: \n",
    "  - **Precision**: 0.78, **Recall**: 0.60, **F1-score**: 0.67\n",
    "  - Decent performance, accounting for partially correct matches.\n",
    "  \n",
    "- **Strict**: \n",
    "  - **Precision**: 0.70, **Recall**: 0.54, **F1-score**: 0.61\n",
    "  - Lower scores due to missed entities and stricter matching criteria.\n",
    "\n",
    "- **Exact**:\n",
    "  - **Precision**: 0.70, **Recall**: 0.54, **F1-score**: 0.61\n",
    "  - Similar to Strict, reflecting the challenges of exact matching.\n",
    "    \n",
    "**Summary**\n",
    "- DATE is one of the best-performing entity types, particularly in less strict evaluations, with balanced precision and recall.\n",
    "- NAME performs poorly across all evaluations, with low precision and recall.\n",
    "- AGE shows high precision but low recall, indicating many missed extractions.\n",
    "- LOCATION achieves relatively strong results, particularly in type-based evaluations, with high precision and recall.\n",
    "- The Strict and Exact evaluations highlight the limitations of the model under stringent criteria, while Ent_Type - - and Partial provide better overall performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24be7e29-47a4-4dd7-b336-c3a40221be0d",
   "metadata": {},
   "source": [
    "## <span style=\"color:darkred; font-weight:bold;\">Strategy 2: NER with Regular Expression  </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ea7256-4562-4b1c-bb89-499c1836fd45",
   "metadata": {},
   "source": [
    "This strategy uses regular expressions (regex) to extract the four types the of entities from a given text. Each entity type is extracted using specific regex patterns designed to handle variations in how each entity can appear in the text. \n",
    "\n",
    "### Full Pipeline:\n",
    "The **`extract_and_classify_entities`** function extracts entities using the regex patterns defined earlier and classifies them into four categories: **NAME**, **DATE**, **LOCATION**, and **AGE**. It prints the results and returns a dictionary containing the start and end positions along with the extracted text for each entity.\n",
    "\n",
    "1. **Name (TITLE + NAME)**:  \n",
    "   - **Covers**:  \n",
    "     This pattern captures names that start with titles such as \"Dr.\", \"Mr.\", \"Ms.\", \"Mrs.\", or \"Prof.\" followed by one or more parts of a proper name (e.g., \"John Doe\").\n",
    "   - **Handling cases**:  \n",
    "     The title is excluded from the captured name, and it skips any name starting with stop words like \"from\", \"the\", etc.\n",
    "\n",
    "2. **Date**:  \n",
    "   - **Covers**:  \n",
    "     Matches various date formats such as:\n",
    "     - Year (e.g., 2023)\n",
    "     - Date in `YYYY-MM-DD` or `MM-DD-YYYY` formats\n",
    "     - Month-year combinations (e.g., May 2022, March/2023)\n",
    "     - Month, Day, Year combinations (e.g., May 22, 2023)\n",
    "   - **Handling cases**:  \n",
    "    Supports different delimiters (like -, /, .) and formats, handling month names in both full and abbreviated forms, excluding the word 'may' but  accepting 'May' only as a valid date\n",
    "\n",
    "3. **Location**:  \n",
    "   - **Covers**:  \n",
    "     This pattern captures locations in various formats, including:\n",
    "     - Locations with context phrases like \"from\" or \"located in\" (e.g., \"from Paris\")\n",
    "     - City names (e.g., \"New York city\")\n",
    "     - Street addresses (e.g., \"5th Avenue\")\n",
    "     - Hospitals (e.g., \"General Hospital\")\n",
    "     - Certain known locations like \"SQU\" or \"FAMCO\", due to the source of reports \n",
    "   - **Handling cases**:  \n",
    "     - Ignores locations that are month names (e.g., \"January\", \"Feb\") to avoid confusion.\n",
    "     - Removes stop words from the start of location strings (e.g., \"from\", \"the\").\n",
    "\n",
    "4. **Age**:  \n",
    "   - **Covers**:  \n",
    "     Matches age-related phrases in various formats like:\n",
    "     - \"I'm 32 years old\"\n",
    "     - \"45-year-old\"\n",
    "     - \"32 yo\"\n",
    "   - **Handling cases**:  \n",
    "     - Accepts age values expressed in several common ways (e.g., \"32 years old\" or \"32 yo\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5518a5b6-5b7b-4beb-8616-463bf1c89ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "MONTHS = {\n",
    "    \"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"Decemebr\",\n",
    "    \"Jan\", \"Feb\", \"Mar\", \"Apr\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"\n",
    "}\n",
    "\n",
    "def extract_entities(text):\n",
    "    \"\"\"\n",
    "    Extract entities using regex patterns.\n",
    "    \"\"\"\n",
    "    stop_words = { \"from\" ,\"the\", \"and\", \"in\", \"on\", \"at\", \"with\", \"for\", \"of\", \"by\", \"a\", \"an\", \"is\", \"are\", \"was\", \"were\", \"to\", \"it\", \"he\", \"she\", \"they\", \"this\", \"that\"}\n",
    "\n",
    "    entities = {\"NAME\": [], \"DATE\": [], \"LOCATION\": [], \"AGE\": []}\n",
    "\n",
    "   \n",
    "    name_pattern = r\"(Dr\\.?|Mr\\.?|Ms\\.?|Mrs\\.?|Prof\\.?)\\s([A-Z][a-z]+(?:\\s[A-Z][a-z]+)*)\"\n",
    "\n",
    "    \n",
    "    for match in re.finditer(name_pattern, text):\n",
    "        start, end = match.span(2) \n",
    "        name = match.group(2)\n",
    "        if name.split()[0] not in stop_words:\n",
    "            entities[\"NAME\"].append((start, end, name))\n",
    "            \n",
    "    dates_pattern = r\"\"\"\n",
    "        \\b(?:  # Word boundary and non-capturing group\n",
    "            \\d{4}(?=\\D|$)  # Standalone year (e.g., 2023), not followed by a digit\n",
    "            |\n",
    "            \\d{4}[-/.]\\d{1,2}[-/.]\\d{1,2}  # YYYY-MM-DD, YYYY/MM/DD\n",
    "            |\n",
    "            \\d{1,2}[-/]\\d{1,2}[-/]\\d{2,4}  # MM-DD-YYYY, DD/MM/YYYY\n",
    "            |\n",
    "            (?:Jan(?:uary)?|Feb(?:ruary)?|Mar(?:ch)?|Apr(?:il)?|May|Jun(?:e)?|Jul(?:y)?|Aug(?:ust)?|Sep(?:tember)?|Oct(?:ober)?|Nov(?:ember)?|Dec(?:ember)?)\n",
    "            \\s?\\d{4}  # Month YYYY or MonthYYYY (e.g., December2011, December 2011)\n",
    "            |\n",
    "            # Month/YYYY (e.g., November/2023)\n",
    "            (?:Jan(?:uary)?|Feb(?:ruary)?|Mar(?:ch)?|Apr(?:il)?|May|Jun(?:e)?|Jul(?:y)?|Aug(?:ust)?|Sep(?:tember)?|Oct(?:ober)?|Nov(?:ember)?|Dec(?:ember)?)\n",
    "            /?\\d{4}\n",
    "            |\n",
    "            # Month DD, YYYY (e.g., May 22, 2023)\n",
    "            (?:Jan(?:uary)?|Feb(?:ruary)?|Mar(?:ch)?|Apr(?:il)?|May|Jun(?:e)?|Jul(?:y)?|Aug(?:ust)?|Sep(?:tember)?|Oct(?:ober)?|Nov(?:ember)?|Dec(?:ember)?)\n",
    "            \\s\\d{1,2},\\s\\d{4}\n",
    "            |\n",
    "            \\b(?:Jan(?:uary)?|Feb(?:ruary)?|Mar(?:ch)?|Apr(?:il)?|(?:May(?!\\b(?!\\s\\d)))|Jun(?:e)?|Jul(?:y)?|Aug(?:ust)?|Sep(?:tember)?|Oct(?:ober)?|Nov(?:ember)?|Dec(?:ember)?)\\b\n",
    "            |\n",
    "            # DD Month YYYY (e.g., 22 May 2016)\n",
    "            \\d{1,2}\\s(?:Jan(?:uary)?|Feb(?:ruary)?|Mar(?:ch)?|Apr(?:il)?|May|Jun(?:e)?|Jul(?:y)?|Aug(?:ust)?|Sep(?:tember)?|Oct(?:ober)?|Nov(?:ember)?|Dec(?:ember)?)\n",
    "            \\s\\d{4}\n",
    "        )\n",
    "    \"\"\"\n",
    "    for match in re.finditer(dates_pattern, text, re.VERBOSE| re.IGNORECASE):\n",
    "    \n",
    "        start, end = match.span()\n",
    "        entities[\"DATE\"].append((start, end, match.group(0)))\n",
    "\n",
    "    \n",
    "    locations_pattern = r\"\"\"\n",
    "    (?:from|located in|live in|resides in|based in|in|at|to)\\s+([A-Z][a-z]+(?:\\s[A-Z][a-z]+)*)  # Contextual locations (e.g., \"from Paris\")\n",
    "    | \\b(?:in|at)\\s+([A-Z]{3,}(?:\\s[A-Z]{2,})*)                                         # Lowercase locations preceded by \"in\" or \"at\"\n",
    "    | \\b(?:In|At)\\s+([A-Z]{3,}(?:\\s[A-Z]{2,})*)                                 # Locations preceded by \"in\" or \"at\" with uppercase locations >= 3 chars (e.g., \"At NYC\")\n",
    "    | ([A-Za-z][a-z]*\\s(?:[A-Z][a-z]+|[a-z]+)\\s(?:Hospital|hospital))  # Locations followed by \"Hospital\"/\"hospital\"\n",
    "    | (\\b[A-Za-z][a-z]+(?:\\s[A-Za-z][a-z]+)*\\s+city\\b)                                  # Locations followed by \"city\" (e.g., \"New York city\")\n",
    "    | (\\b(?:Street|street|Avenue|avenue|Boulevard|boulevard|Road|road|Lane|lane|Square|square|Park|park|Hill|hill|Circle|circle|Court|court|Drive|drive|Plaza|plaza|Terrace|terrace)\\b\\s+[A-Za-z][a-z]+(?:\\s[A-Za-z][a-z]+)*)  # Street/road/place names\n",
    "    | (\\b[A-Za-z][a-z]+(?:\\s[A-Z][a-z]+)*\\s+(?:Park|park)\\b)                           # Locations followed by \"Park\"/\"park\"\n",
    "    | (\\b[A-Z][a-z]+(?:\\s[A-Z][a-z]+)*\\s+(?:Region|region)\\b)                          # Locations followed by \"Region\"/\"region\"\n",
    "    | (\\b[A-Z][a-z]+(?:\\s[A-Z][a-z]+)*\\s+(?:National|national)\\b)                      # Locations followed by \"National\"/\"national\"\n",
    "    | (\\b[A-Z][a-z]+(?:\\s[A-Z][a-z]+)*\\s+(?:State|state)\\b)                            # Locations followed by \"State\"/\"state\"\n",
    "    | (\\b[A-Z][a-z]+(?:\\s[A-Z][a-z]+)*\\s+(?:Country|country)\\b)                        # Locations followed by \"Country\"/\"country\"\n",
    "    | (\\b[A-Z][a-z]+(?:\\s[A-Z][a-z]+)*\\s+(?:Continent|continent)\\b)                    # Locations followed by \"Continent\"/\"continent\"\n",
    "    | \\b(SQU|FAMCO)\\b  # Locations matching \"SQU\" or \"FAMCO\"\n",
    "    \"\"\"\n",
    "\n",
    "    for match in re.finditer(locations_pattern, text, re.VERBOSE):\n",
    "        location = match.group(0)\n",
    "        \n",
    "        len_stop = 1\n",
    "        location_parts = location.split()\n",
    "        if location_parts[0].lower() in stop_words:\n",
    "            location = \" \".join(location_parts[1:])\n",
    "            len_stop += len(location_parts[0])\n",
    "\n",
    "         \n",
    "        if location.split()[0] in MONTHS:\n",
    "             continue  # Skip this location\n",
    "        # Ensure the cleaned location is not a stop word itself\n",
    "        if location.lower() not in stop_words:\n",
    "            start, end = match.span()\n",
    "            entities[\"LOCATION\"].append((start+len_stop, end, location))\n",
    "\n",
    "    \n",
    "    ages_pattern = r\"\\b(\\d{1,3})\\s?(?:years?\\s?old|yrs?\\s?old|-year-old|yo)\\b\"\n",
    "    \n",
    "    for match in re.finditer(ages_pattern, text):\n",
    "        start, end = match.span(1)  # Get the span of only the numeric part (group 1)\n",
    "        age_value = match.group(1).strip()  # Capture only the numeric value (e.g., '45')\n",
    "        entities[\"AGE\"].append((start, end, age_value))\n",
    "\n",
    "    return entities\n",
    "\n",
    "# Full workflow: Combine regex extraction and POS tagging\n",
    "def extract_and_classify_entities(text):\n",
    "    \"\"\"\n",
    "    Full pipeline to extract and classify entities.\n",
    "    \"\"\"\n",
    "    \n",
    "    regex_entities = extract_entities(text)\n",
    "    print(\"\\nEntities Extracted Using Regex:\")\n",
    "    for entity_type, values in regex_entities.items():\n",
    "        print(f\"{entity_type}: {values}\")\n",
    "\n",
    "    return regex_entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ca7228e-e191-4c07-ab17-33274491a086",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "folder_path = \"to test\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "594428b9-44f5-42bc-b279-2f213bbefde8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Overall\n",
      "              correct   incorrect     partial      missed    spurious   precision      recall    f1-score\n",
      "\n",
      "ent_type          168           0           0          25          21        0.89        0.87        0.88\n",
      " partial          143           0          25          25          21        0.82        0.81        0.81\n",
      "  strict          143          25           0          25          21        0.76        0.74        0.75\n",
      "   exact          143          25           0          25          21        0.76        0.74        0.75\n",
      "\n",
      "\n",
      "\n",
      "'Strict'\n",
      "              correct   incorrect     partial      missed    spurious   precision      recall    f1-score\n",
      "\n",
      "     AGE           14           0           0           3           9        0.61        0.82        0.70\n",
      "    DATE           94           5           0           6           5        0.90        0.90        0.90\n",
      "LOCATION           29          10           0          11           7        0.63        0.58        0.60\n",
      "    NAME            6          10           0           5           0        0.38        0.29        0.32\n",
      "\n",
      "\n",
      "\n",
      "'Ent_Type'\n",
      "              correct   incorrect     partial      missed    spurious   precision      recall    f1-score\n",
      "\n",
      "     AGE           14           0           0           3           9        0.61        0.82        0.70\n",
      "    DATE           99           0           0           6           5        0.95        0.94        0.95\n",
      "LOCATION           39           0           0          11           7        0.85        0.78        0.81\n",
      "    NAME           16           0           0           5           0        1.00        0.76        0.86\n",
      "\n",
      "\n",
      "\n",
      "'Partial'\n",
      "              correct   incorrect     partial      missed    spurious   precision      recall    f1-score\n",
      "\n",
      "     AGE           14           0           0           3           9        0.61        0.82        0.70\n",
      "    DATE           94           0           5           6           5        0.93        0.92        0.92\n",
      "LOCATION           29           0          10          11           7        0.74        0.68        0.71\n",
      "    NAME            6           0          10           5           0        0.69        0.52        0.59\n",
      "\n",
      "\n",
      "\n",
      "'Exact'\n",
      "              correct   incorrect     partial      missed    spurious   precision      recall    f1-score\n",
      "\n",
      "     AGE           14           0           0           3           9        0.61        0.82        0.70\n",
      "    DATE           94           5           0           6           5        0.90        0.90        0.90\n",
      "LOCATION           29          10           0          11           7        0.63        0.58        0.60\n",
      "    NAME            6          10           0           5           0        0.38        0.29        0.32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluation\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import csv\n",
    "from nervaluate import Evaluator, summary_report_overall, summary_report_ent\n",
    "\n",
    "txt_files = {}\n",
    "csv_files = {}\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    if filename.endswith(\".txt\"):\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            txt_files[filename] = file.read()  \n",
    "    elif filename.endswith(\".csv\"):\n",
    "        data = pd.read_csv(file_path)  \n",
    "        csv_files[filename] = data  \n",
    "\n",
    "\n",
    "predicted_entities = []\n",
    "for d in txt_files.keys():\n",
    "    txt = txt_files[d]\n",
    "    ner_entities = extract_entities(txt)\n",
    "    \n",
    "    doc_entities = []\n",
    "    for tag in ner_entities:\n",
    "        for entity in ner_entities[tag]:\n",
    "            doc_entities.append({\"label\": tag, \"start\": entity[0], \"end\": entity[1]})\n",
    "    predicted_entities.append(doc_entities)\n",
    "\n",
    "\n",
    "true_entities = []\n",
    "for d in txt_files.keys():\n",
    "    csv_filename = d.replace('.txt', '.csv')  \n",
    "    if csv_filename in csv_files:\n",
    "        data = csv_files[csv_filename]\n",
    "        doc_entities = []\n",
    "        for _, row in data.iterrows():\n",
    "            doc_entities.append({\"label\": row['tag'], \"start\": int(row['start']), \"end\": int(row['end'])})\n",
    "        true_entities.append(doc_entities)\n",
    "\n",
    "\n",
    "from nervaluate import Evaluator\n",
    "from nervaluate import summary_report_overall, summary_report_ent\n",
    "\n",
    "evaluator = Evaluator(true_entities, predicted_entities, tags=['LOCATION', 'NAME', 'DATE', 'AGE'])\n",
    "\n",
    "results, results_per_tag, result_indices, result_indices_by_tag = evaluator.evaluate()\n",
    "\n",
    "print(\"\\n\\nOverall\")\n",
    "print(summary_report_overall(results))\n",
    "print(\"\\n\\n'Strict'\")\n",
    "print(summary_report_ent(results_per_tag, scenario=\"strict\"))\n",
    "print(\"\\n\\n'Ent_Type'\")\n",
    "print(summary_report_ent(results_per_tag, scenario=\"ent_type\"))\n",
    "print(\"\\n\\n'Partial'\")\n",
    "print(summary_report_ent(results_per_tag, scenario=\"partial\"))\n",
    "print(\"\\n\\n'Exact'\")\n",
    "print(summary_report_ent(results_per_tag, scenario=\"exact\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d3c3e52-3221-433f-bf45-82c18269ae76",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = \"test\"  \n",
    "output_folder = \"output_csv\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d0b2b85-6ff3-436b-ba75-230c22c73a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: p202_prostate_onc_1.txt\n",
      "Saved extracted entities to: output_csv\\p202_prostate_onc_1.csv\n",
      "Processing file: p203_prostate_onc_10.txt\n",
      "Saved extracted entities to: output_csv\\p203_prostate_onc_10.csv\n",
      "Processing file: p204_prostate_onc_23.txt\n",
      "Saved extracted entities to: output_csv\\p204_prostate_onc_23.csv\n",
      "Processing file: p205_prostate_onc_5.txt\n",
      "Saved extracted entities to: output_csv\\p205_prostate_onc_5.csv\n",
      "Processing file: p206_prostate_onc_4.txt\n",
      "Saved extracted entities to: output_csv\\p206_prostate_onc_4.csv\n",
      "Processing file: p208_prostate_onc_4.txt\n",
      "Saved extracted entities to: output_csv\\p208_prostate_onc_4.csv\n",
      "Processing file: p209_prostate_onc_3.txt\n",
      "Saved extracted entities to: output_csv\\p209_prostate_onc_3.csv\n",
      "Processing file: p210_prostate_onc_7.txt\n",
      "Saved extracted entities to: output_csv\\p210_prostate_onc_7.csv\n",
      "Processing file: p211_prostate_onc_5.txt\n",
      "Saved extracted entities to: output_csv\\p211_prostate_onc_5.csv\n",
      "Processing file: p212_prostate_onc_4.txt\n",
      "Saved extracted entities to: output_csv\\p212_prostate_onc_4.csv\n",
      "Processing file: p213_prostate_onc_8.txt\n",
      "Saved extracted entities to: output_csv\\p213_prostate_onc_8.csv\n",
      "Processing file: p214_prostate_onc_8.txt\n",
      "Saved extracted entities to: output_csv\\p214_prostate_onc_8.csv\n",
      "Processing file: p216_prostate_onc_5.txt\n",
      "Saved extracted entities to: output_csv\\p216_prostate_onc_5.csv\n",
      "Processing file: p217_prostate_onc_1.txt\n",
      "Saved extracted entities to: output_csv\\p217_prostate_onc_1.csv\n",
      "Processing file: p218_prostate_onc_2.txt\n",
      "Saved extracted entities to: output_csv\\p218_prostate_onc_2.csv\n",
      "Processing file: p219_prostate_onc_10.txt\n",
      "Saved extracted entities to: output_csv\\p219_prostate_onc_10.csv\n",
      "Processing file: p220_prostate_sur_6.txt\n",
      "Saved extracted entities to: output_csv\\p220_prostate_sur_6.csv\n",
      "Processing file: p221_prostate_onc_7.txt\n",
      "Saved extracted entities to: output_csv\\p221_prostate_onc_7.csv\n",
      "Processing file: p222_prostate_onc_6.txt\n",
      "Saved extracted entities to: output_csv\\p222_prostate_onc_6.csv\n",
      "Processing file: p223_prostate_onc_4.txt\n",
      "Saved extracted entities to: output_csv\\p223_prostate_onc_4.csv\n",
      "Processing file: p224_prostate_onc_8.txt\n",
      "Saved extracted entities to: output_csv\\p224_prostate_onc_8.csv\n",
      "Processing file: p225_prostate_onc_4.txt\n",
      "Saved extracted entities to: output_csv\\p225_prostate_onc_4.csv\n",
      "Processing file: p226_prostate_onc_7.txt\n",
      "Saved extracted entities to: output_csv\\p226_prostate_onc_7.csv\n",
      "Processing file: p227_prostate_onc_6.txt\n",
      "Saved extracted entities to: output_csv\\p227_prostate_onc_6.csv\n",
      "Processing file: p228_prostate_onc_5.txt\n",
      "Saved extracted entities to: output_csv\\p228_prostate_onc_5.csv\n",
      "Processing file: p229_prostate_onc_5.txt\n",
      "Saved extracted entities to: output_csv\\p229_prostate_onc_5.csv\n",
      "Processing file: p231_breast_onc_20.txt\n",
      "Saved extracted entities to: output_csv\\p231_breast_onc_20.csv\n",
      "Processing file: p232_breast_onc_9.txt\n",
      "Saved extracted entities to: output_csv\\p232_breast_onc_9.csv\n",
      "Processing file: p233_breast_sur_5.txt\n",
      "Saved extracted entities to: output_csv\\p233_breast_sur_5.csv\n",
      "Processing file: p234_breast_sur_3.txt\n",
      "Saved extracted entities to: output_csv\\p234_breast_sur_3.csv\n",
      "Processing file: p235_breast_sur_5.txt\n",
      "Saved extracted entities to: output_csv\\p235_breast_sur_5.csv\n",
      "Processing file: p237_breast_onc_6.txt\n",
      "Saved extracted entities to: output_csv\\p237_breast_onc_6.csv\n",
      "Processing file: p238_breast_sur_4.txt\n",
      "Saved extracted entities to: output_csv\\p238_breast_sur_4.csv\n",
      "Processing file: p239_breast_onc_18.txt\n",
      "Saved extracted entities to: output_csv\\p239_breast_onc_18.csv\n",
      "Processing file: p240_breast_onc_13.txt\n",
      "Saved extracted entities to: output_csv\\p240_breast_onc_13.csv\n",
      "Processing file: p241_breast_sur_13.txt\n",
      "Saved extracted entities to: output_csv\\p241_breast_sur_13.csv\n",
      "Processing file: p242_breast_sur_6.txt\n",
      "Saved extracted entities to: output_csv\\p242_breast_sur_6.csv\n",
      "Processing file: p244_breast_onc_13.txt\n",
      "Saved extracted entities to: output_csv\\p244_breast_onc_13.csv\n",
      "Processing file: p245_breast_onc_11.txt\n",
      "Saved extracted entities to: output_csv\\p245_breast_onc_11.csv\n",
      "Processing file: p246_breast_onc_5.txt\n",
      "Saved extracted entities to: output_csv\\p246_breast_onc_5.csv\n",
      "Processing file: p247_breast_onc_15.txt\n",
      "Saved extracted entities to: output_csv\\p247_breast_onc_15.csv\n",
      "Processing file: p248_breast_onc_13.txt\n",
      "Saved extracted entities to: output_csv\\p248_breast_onc_13.csv\n",
      "Processing file: p249_breast_sur_10.txt\n",
      "Saved extracted entities to: output_csv\\p249_breast_sur_10.csv\n",
      "Processing file: p250_breast_sur_9.txt\n",
      "Saved extracted entities to: output_csv\\p250_breast_sur_9.csv\n",
      "Processing file: p251_breast_onc_82.txt\n",
      "Saved extracted entities to: output_csv\\p251_breast_onc_82.csv\n",
      "Processing file: p252_breast_sur_6.txt\n",
      "Saved extracted entities to: output_csv\\p252_breast_sur_6.csv\n",
      "Processing file: p253_breast_sur_2.txt\n",
      "Saved extracted entities to: output_csv\\p253_breast_sur_2.csv\n",
      "Processing file: p254_breast_onc_19.txt\n",
      "Saved extracted entities to: output_csv\\p254_breast_onc_19.csv\n",
      "Processing file: p256_breast_onc_11.txt\n",
      "Saved extracted entities to: output_csv\\p256_breast_onc_11.csv\n",
      "Processing file: p257_breast_onc_7.txt\n",
      "Saved extracted entities to: output_csv\\p257_breast_onc_7.csv\n",
      "Processing file: p258_breast_onc_14.txt\n",
      "Saved extracted entities to: output_csv\\p258_breast_onc_14.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "\n",
    "def save_entities_to_csv(entities, output_csv_path):\n",
    "    \"\"\"\n",
    "    Save the extracted entities to a CSV file in the specified format.\n",
    "    \"\"\"\n",
    "    # Prepare the data to be written to the CSV file\n",
    "    rows = []\n",
    "    for entity_type, values in entities.items():\n",
    "        for start, end, entity in values:\n",
    "            rows.append([start, end, entity_type, entity])\n",
    "\n",
    "    # Write to CSV with the specified column names\n",
    "    with open(output_csv_path, mode=\"w\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerow([\"start\", \"end\", \"tag\", \"text\"])  # CSV header\n",
    "        writer.writerows(rows)\n",
    "\n",
    "def process_text_files(input_folder, output_folder):\n",
    "    \"\"\"\n",
    "    Process each .txt file in the folder, extract entities and save to corresponding CSV file.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    \n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".txt\"):  \n",
    "            txt_file_path = os.path.join(input_folder, filename)\n",
    "            print(f\"Processing file: {filename}\")\n",
    "\n",
    "            \n",
    "            with open(txt_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                text = file.read()\n",
    "\n",
    "           \n",
    "            entities = extract_entities(text)\n",
    "\n",
    "            \n",
    "            output_csv_path = os.path.join(output_folder, f\"{os.path.splitext(filename)[0]}.csv\")\n",
    "\n",
    "            \n",
    "            save_entities_to_csv(entities, output_csv_path)\n",
    "            print(f\"Saved extracted entities to: {output_csv_path}\")\n",
    "\n",
    "# Process the text files\n",
    "process_text_files(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a96b84e-13cd-4f37-8bf1-a60cb1196b3b",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkred; font-weight:bold;\"> Entity Extraction with Regular Expression Evaluation Summary </span>\n",
    "**Overall Evaluation**\n",
    "\n",
    "- **Ent_Type**: \n",
    "  - **Precision**: 0.89, **Recall**: 0.87, **F1-score**: 0.88\n",
    "  - Strong performance with most entities correctly identified.\n",
    "  \n",
    "- **Partial**: \n",
    "  - **Precision**: 0.82, **Recall**: 0.81, **F1-score**: 0.81\n",
    "  - Decent performance with some missed entities and spurious results.\n",
    "  \n",
    "- **Strict**: \n",
    "  - **Precision**: 0.76, **Recall**: 0.74, **F1-score**: 0.75\n",
    "  - Lower performance due to missed entities and spurious results.\n",
    "\n",
    "- **Exact**:\n",
    "  - **Precision**: 0.76, **Recall**: 0.74, **F1-score**: 0.75\n",
    "  - Similar to **Strict**; performance drops due to stricter evaluation.\n",
    "    \n",
    "**Summary**\n",
    "- **DATE** is the best-performing entity type across all scenarios, with very high precision and recall.\n",
    "- **NAME** consistently performs poorly, with low precision and recall.\n",
    "- **AGE** and **LOCATION** show moderate performance with relatively high recall but lower precision.\n",
    "- The **Strict** and **Exact** scenarios yield the lowest performance due to stricter matching criteria, while **Ent_Type** and **Partial** offer better flexibility and higher F1-scores."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
